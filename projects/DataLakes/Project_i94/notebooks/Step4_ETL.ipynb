{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project i94\n",
    "##### (Step4_ETL.ipynb)\n",
    "**Note:** This notebook includes the following work steps:\n",
    "* Data pipelines run\n",
    "* Data integrity & quality inspection \n",
    "\n",
    "---\n",
    "\n",
    "- This step can actually be automated by running [**etl.py**](./etl.py) on the terminal\n",
    "> \\>> `python etl.py`\n",
    " \n",
    "- Alternatively, each work step can be imported and run in this notebook (as shown below)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types as T \n",
    "\n",
    "from utility_functions import cleaning_immigration_data, cleaning_demographic_data\n",
    "from utility_functions import quality_check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start spark session\n",
    "spark = (SparkSession \n",
    "            .builder \n",
    "            .config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\") \n",
    "            .enableHiveSupport().getOrCreate()\n",
    "        )\n",
    "\n",
    "input_data = '../data/'\n",
    "output_data = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dimension table from immigration data\n",
    "- due to size limitation the sas file is not included in this repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get filepath to the immigration data file\n",
    "immigration_data = os.path.join(input_data,\"18-83510-I94-Data-2016/i94_{}16_sub.sas7bdat\")\n",
    "month= 'apr'\n",
    "\n",
    "# read i94_immigration data file\n",
    "df = (spark.read.format('com.github.saurfang.sas.spark') \n",
    "            .load(immigration_data.format(month))\n",
    "    )\n",
    "\n",
    "# clean and prep immigration data \n",
    "df = cleaning_immigration_data(df)\n",
    "\n",
    "# extract columns to create dimension table\n",
    "dim_immigration_table = (df.groupBy(['year', 'month','entry_port','destination_state',\n",
    "                                    'citizenship','age','purpose',\n",
    "                                    'visa_type']).agg({'count':'sum'})\n",
    "                        .withColumnRenamed(\"sum(count)\", \"count\")\n",
    "                        ).dropna()\n",
    "\n",
    "# write dim table to parquet files partitioned by destination_state \n",
    "dim_immigration_table.write.mode('append').partitionBy('destination_state').parquet(output_data+'dim_immigration.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dimension table from demographic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read demographic data file\n",
    "df = (spark.read.format('csv')\n",
    "                         .option(\"header\",\"true\")\n",
    "                         .option(\"inferSchema\",\"true\")\n",
    "                         .option(\"sep\",\";\")\n",
    "                         .load('../data/us-cities-demographics.csv')\n",
    "                    )\n",
    "\n",
    "# clean and prep demographic data \n",
    "df = cleaning_demographic_data(df)\n",
    "\n",
    "# extract columns for dim table    \n",
    "dim_demographic_table = df.select(['state_code','city','median_age','foreign_born',\n",
    "                                   'total_population','race','race_count'])\n",
    "\n",
    "# write dim demographic table to parquet files partitioned by destination_state \n",
    "dim_demographic_table.write.mode('append').partitionBy('state_code').parquet(output_data+'dim_demographic.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create fact table from joining some columns from the dimension tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create temporary views of the immigration and demographic data\n",
    "dim_immigration_table.createOrReplaceTempView(\"immigration_view\")\n",
    "dim_demographic_table.createOrReplaceTempView(\"demographic_view\")\n",
    "\n",
    "# Create the fact table by joining the immigration and demographic views\n",
    "fact_table = spark.sql('''\n",
    "    SELECT i.year AS year,\n",
    "        i.month AS month,\n",
    "        i.citizenship AS origin_country,\n",
    "        i.entry_port AS entry_port,\n",
    "        i.visa_type AS visa_type,\n",
    "        i.purpose AS visit_purpose,\n",
    "        i.destination_state AS state_code,\n",
    "        d.city AS city,\n",
    "        d.total_population AS city_population,\n",
    "        SUM(i.count) AS immigration_count\n",
    "    FROM immigration_view AS i\n",
    "    JOIN demographic_view AS d \n",
    "        ON (i.destination_state = d.state_code)\n",
    "    GROUP BY \n",
    "        1, 2, 3, 4, 5, 6, 7, 8, 9 \n",
    "    ''')\n",
    "\n",
    "# Write fact table to parquet files partitioned by state\n",
    "fact_table.write.mode(\"append\").partitionBy(\"state_code\").parquet(output_data+\"fact_table.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    " Definition of function is described in [**utility_functions.py**](./utility_functions.py)\n",
    " * Check number of total rows to ensure completeness\n",
    " * Check for null values in each column of tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality check for **demographic** dimension table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing quality checks for demographic dimension table\n",
      "Number of null values for state_code is: 0\n",
      "Number of null values for city is: 0\n",
      "Number of null values for median_age is: 0\n",
      "Number of null values for foreign_born is: 0\n",
      "Number of null values for total_population is: 0\n",
      "Number of null values for race is: 0\n",
      "Number of null values for race_count is: 0\n",
      "Total number of rows is: 2875\n"
     ]
    }
   ],
   "source": [
    "quality_check(dim_demographic_table,'demographic dimension table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality check for **immigration** dimension table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing quality checks for immigration dimension table\n",
      "Number of null values for year is: 0\n",
      "Number of null values for month is: 0\n",
      "Number of null values for entry_port is: 0\n",
      "Number of null values for destination_state is: 0\n",
      "Number of null values for citizenship is: 0\n",
      "Number of null values for age is: 0\n",
      "Number of null values for purpose is: 0\n",
      "Number of null values for visa_type is: 0\n",
      "Number of null values for count is: 0\n",
      "Total number of rows is: 856233\n"
     ]
    }
   ],
   "source": [
    "quality_check(dim_immigration_table, 'immigration dimension table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality check for **fact** table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing quality checks for fact table\n",
      "Number of null values for year is: 0\n",
      "Number of null values for month is: 0\n",
      "Number of null values for origin_country is: 0\n",
      "Number of null values for entry_port is: 0\n",
      "Number of null values for visa_type is: 0\n",
      "Number of null values for visit_purpose is: 0\n",
      "Number of null values for state_code is: 0\n",
      "Number of null values for city is: 0\n",
      "Number of null values for city_population is: 0\n",
      "Number of null values for immigration_count is: 0\n",
      "Total number of rows is: 3233402\n"
     ]
    }
   ],
   "source": [
    "quality_check(fact_table, 'fact table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "\n",
    "**Dimensional Table-1**:  immigration dataset\n",
    "- **year**: 4-digit calendar year of visitor's arrival\n",
    "- **month**: Calendar month of visitor's arrival\n",
    "- **entry_port**: 3-digit code for visitor's port of entry, as defined [here](../data/port_dictionary.txt) \n",
    "- **destination_state**: Abbreviated state code of visitor's destination\n",
    "- **citizenship**: 3-digit code for visitor's country of origin, as defined [here](../data/country_code_dictionary.txt) \n",
    "- **age**: Age of visitor at the time of arrival\n",
    "- **purpose**: Purpose of visit, e.g., 1: business, 2: pleasure, 3: student \n",
    "- **visa_type**: Visa types, e.g., F1, F2, B1, etc.\n",
    "- **count**: Total number of arrivals\n",
    "\n",
    "**Dimensional Table-2**: demographic dataset\n",
    "- **state_code**: Abbreviated state code\n",
    "- **city**: city name\n",
    "- **median_age**: median age in city\n",
    "- **foreign_born**: number of foreign-born residents \n",
    "- **total_population**: Size of population in city\n",
    "- **race**: Ethnic race in city\n",
    "- **race_count**: Size of ethnic population in city\n",
    "\n",
    "**Fact Table**: Joined from immigration & demographic datasets\n",
    "- **year**: 4-digit calendar year of visitor's arrival\n",
    "- **month**: Calendar month of visitor's arrival\n",
    "- **origin_country**: 3-digit code for visitor's country of origin \n",
    "- **entry_port**: 3-digit code for visitor's port of entry\n",
    "- **visa_type**: Visa types, e.g., F1, F2, B1, etc.\n",
    "- **visit_purpose**: Purpose of visit, e.g., 1: business, 2: pleasure, 3: student \n",
    "- **state_code**: Abbreviated state code\n",
    "- **city**: city name\n",
    "- **city_population**: Size of population in city\n",
    "- **immigration_count**: total number of arrivals  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next:** [Project Summary](./Step5_Summary.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
